{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import subprocess\n",
    "import cv2\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# Set the working directory to the notebook location\n",
    "notebook_dir = os.getcwd()  # Get current working directory of the notebook\n",
    "\n",
    "# Ensure custom module paths are included\n",
    "tracking_diagnostics_path = os.path.abspath(os.path.join(notebook_dir, 'tracking-diagnostics'))\n",
    "\n",
    "sys.path.append(tracking_diagnostics_path)\n",
    "\n",
    "from diagnostics.video import get_frames_from_idxs\n",
    "from eks.utils import convert_lp_dlc, format_data\n",
    "from pseudo_labeler.utils import format_data_walk\n",
    "from pseudo_labeler.evaluation import compute_likelihoods_and_variance, plot_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: /teamspace/studios/this_studio/outputs/mirror-mouse/hand=100_pseudo=1000\n",
      "Videos Directory: /teamspace/studios/this_studio/data/mirror-mouse\n",
      "Number of Frames: 10\n",
      "Excluded Keypoints: ['obs_top', 'obsHigh_bot', 'obsLow_bot']\n",
      "Networks Directory: /teamspace/studios/this_studio/outputs/mirror-mouse/hand=100_pseudo=1000/networks\n",
      "EKS Directory: /teamspace/studios/this_studio/outputs/mirror-mouse/hand=100_pseudo=1000/post-processors/eks_rng=0-3\n",
      "AEKS Directory: /teamspace/studios/this_studio/outputs/mirror-mouse/hand=100_pseudo=1000/results_aeks_random\n",
      "Output Directory: /teamspace/studios/this_studio/outputs/mirror-mouse/hand=100_pseudo=1000/eks_aeks_pixel_diff\n"
     ]
    }
   ],
   "source": [
    "# ADJUST THESE\n",
    "dir = '/teamspace/studios/this_studio/outputs/mirror-mouse/hand=100_pseudo=1000'\n",
    "videos_dir = '/teamspace/studios/this_studio/data/mirror-mouse'  # video to be overlayed on\n",
    "n_frames = 10\n",
    "top_error_frame_count = 3\n",
    "excluded_keypoints = ['obs_top', 'obsHigh_bot', 'obsLow_bot']\n",
    "file_names = ['test_vid', 'test_vid_new']  # the specific video files (e.g. 'test_vid') you want plotted, does all if left blank. \n",
    "# END ADJUST\n",
    "\n",
    "# Define paths relative to the base directory -- these shouldn't change unless using a different baseline\n",
    "networks_dir = os.path.join(dir, 'networks')\n",
    "eks_dir = os.path.join(dir, 'post-processors', 'eks_rng=0-3')  # specify this directory\n",
    "aeks_dir = os.path.join(dir, 'results_aeks_random')\n",
    "output_dir = os.path.join(dir, 'eks_aeks_pixel_diff')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Print paths to verify\n",
    "print(f\"Base Directory: {dir}\")\n",
    "print(f\"Videos Directory: {videos_dir}\")\n",
    "print(f\"Number of Frames: {n_frames}\")\n",
    "print(f\"Excluded Keypoints: {excluded_keypoints}\")\n",
    "print(f\"Networks Directory: {networks_dir}\")\n",
    "print(f\"EKS Directory: {eks_dir}\")\n",
    "print(f\"AEKS Directory: {aeks_dir}\")\n",
    "print(f\"Output Directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def get_subdirectories(directory):\n",
    "    return [os.path.join(directory, sub_dir) for sub_dir in os.listdir(directory) if os.path.isdir(os.path.join(directory, sub_dir))]\n",
    "\n",
    "def get_csv_files(directory, file_name):\n",
    "    pattern = os.path.join(directory, f'**/*{file_name}.csv')\n",
    "    return glob.glob(pattern, recursive=True)\n",
    "\n",
    "def group_csv_files(eks_files, aeks_files):\n",
    "    file_groups = defaultdict(list)\n",
    "    \n",
    "    for file in eks_files:\n",
    "        file_name = os.path.basename(file)\n",
    "        file_groups[file_name].append(file)\n",
    "        \n",
    "    for file in aeks_files:\n",
    "        file_name = os.path.basename(file)\n",
    "        file_groups[file_name].append(file)\n",
    "        \n",
    "    return file_groups\n",
    "\n",
    "def calculate_pixel_error(file1, file2, top_frame_count=20):\n",
    "    df1 = pd.read_csv(file1, header=[0, 1, 2])\n",
    "    df2 = pd.read_csv(file2, header=[0, 1, 2])\n",
    "    \n",
    "    scorer1 = df1.columns.levels[0][0]  # Automatically detect the first-level column header for df1\n",
    "    scorer2 = df2.columns.levels[0][0]  # Automatically detect the first-level column header for df2\n",
    "    \n",
    "    keypoints = df1.columns.get_level_values(1).unique()\n",
    "    errors = defaultdict(list)\n",
    "    top_error_frames = []\n",
    "    \n",
    "    for keypoint in keypoints:\n",
    "        if keypoint == 'bodyparts':\n",
    "            continue\n",
    "        \n",
    "        x1 = df1[scorer1, keypoint, 'x']\n",
    "        y1 = df1[scorer1, keypoint, 'y']\n",
    "        x2 = df2[scorer2, keypoint, 'x']\n",
    "        y2 = df2[scorer2, keypoint, 'y']\n",
    "        \n",
    "        distance = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "        errors[keypoint] = distance\n",
    "        \n",
    "        top_indices = distance.nlargest(top_frame_count).index\n",
    "        top_error_frames.extend([(keypoint, idx, distance[idx]) for idx in top_indices])\n",
    "    \n",
    "    error_df = pd.DataFrame(errors)\n",
    "    top_error_df = pd.DataFrame(top_error_frames, columns=['keypoint', 'frame', 'error'])\n",
    "    return error_df, top_error_df\n",
    "\n",
    "def save_video(save_file, tmp_dir, framerate, frame_pattern='frame_%06d.jpeg'):\n",
    "    call_str = f'ffmpeg -r {framerate} -loglevel error -y -i {os.path.join(tmp_dir, frame_pattern)} -c:v libx264 -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" {save_file}'\n",
    "    if os.name == 'nt':  # If the OS is Windows\n",
    "        subprocess.run(['ffmpeg', '-loglevel', 'error', '-r', str(framerate), '-y', '-i', f'{tmp_dir}/frame_%06d.jpeg',\n",
    "                        '-c:v', 'libx264', '-vf', \"pad=ceil(iw/2)*2:ceil(ih/2)*2\",\n",
    "                        save_file],\n",
    "                       check=True)\n",
    "    else:  # If the OS is Unix/Linux\n",
    "        subprocess.run(['/bin/bash', '-c', call_str], check=True)\n",
    "\n",
    "def plot_video_markers(markers_pd, ax, n, body_part, color, alphas, markers, model_id=0, markersize=8):\n",
    "    x_key = body_part + '_x'\n",
    "    y_key = body_part + '_y'\n",
    "    markers_x = markers_pd[x_key][n]\n",
    "    markers_y = markers_pd[y_key][n]\n",
    "    ax.scatter(markers_x, markers_y, alpha=alphas[model_id], marker=\"o\", color=color)\n",
    "\n",
    "def read_error_files(relative_pixel_error_dir, file_name):\n",
    "    error_data = {}\n",
    "\n",
    "    for subdir, dirs, files in os.walk(relative_pixel_error_dir):\n",
    "        for file in files:\n",
    "            if not file.endswith('.csv'):\n",
    "                continue\n",
    "            if file_name not in file:\n",
    "                continue\n",
    "            try:\n",
    "                model_name = os.path.splitext(file)[0].replace('error_', '')\n",
    "                error_df = pd.read_csv(os.path.join(subdir, file))\n",
    "                error_data[model_name] = error_df\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "    print(f\"Read {len(error_data)} pixel error files into DataFrame.\")\n",
    "    return error_data\n",
    "\n",
    "\n",
    "def expanding_mean(arr):\n",
    "    return np.cumsum(arr) / np.arange(1, len(arr) + 1)\n",
    "\n",
    "def organize_error_files(relative_pixel_error_dir):\n",
    "    error_files = [f for f in os.listdir(relative_pixel_error_dir) if f.endswith('.csv')]\n",
    "    for file in error_files:\n",
    "        file_base_name = file.split('_')[1]\n",
    "        sub_dir = os.path.join(relative_pixel_error_dir, file_base_name)\n",
    "        if not os.path.exists(sub_dir):\n",
    "            os.makedirs(sub_dir)\n",
    "        os.rename(os.path.join(relative_pixel_error_dir, file), os.path.join(sub_dir, file))\n",
    "\n",
    "def find_matching_video(video_dir, base_file_name):\n",
    "    for root, _, files in os.walk(video_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(base_file_name) and file.endswith(('.mp4', '.avi', '.mov')):\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "def find_unique_mp4_basenames(video_dir):\n",
    "    mp4_basenames = set()  # Use a set to store unique base names\n",
    "    for root, dirs, files in os.walk(video_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.mp4'):  # Ensure it matches only .mp4 files\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "                mp4_basenames.add(base_name)\n",
    "            else:\n",
    "                print(f\"Skipping non-mp4 file: {file}\")\n",
    "    return list(mp4_basenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summed_ensemble_variance(networks_dir, output_dir, file_name):\n",
    "    data_type = 'lp'\n",
    "    input_dfs, output_df, _ = format_data_walk(networks_dir, data_type, f'{file_name}.csv')\n",
    "    print(f'Found {len(input_dfs)} models.')\n",
    "    likelihood_thresh = 0.9\n",
    "    likelihoods_above_thresh, summed_ensemble_vars, combined_df, bodypart_list = compute_likelihoods_and_variance(input_dfs, likelihood_thresh)\n",
    "\n",
    "    # Create a DataFrame from summed_ensemble_vars\n",
    "    summed_ensemble_vars_df = pd.DataFrame(summed_ensemble_vars, columns=bodypart_list)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(output_dir, f\"summed_ensemble_vars_{file_name}.csv\")\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    summed_ensemble_vars_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f'Saved summed_ensemble_vars to {output_file_path}')\n",
    "    return output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors_main(eks_dir, aeks_dir, output_dir, file_name, top_error_frame_count=20):\n",
    "    eks_csv_files = get_csv_files(eks_dir, file_name)\n",
    "    if not eks_csv_files:\n",
    "        print(f\"No matching EKS files found for {file_name} in {eks_dir}\")\n",
    "        return {}, []\n",
    "\n",
    "    all_top_error_frames = {}\n",
    "    all_error_dfs = []\n",
    "\n",
    "    aeks_subdirs = [os.path.join(aeks_dir, sub_dir) for sub_dir in os.listdir(aeks_dir) if os.path.isdir(os.path.join(aeks_dir, sub_dir))]\n",
    "    if not aeks_subdirs:\n",
    "        print(f\"No AEKS subdirectories found in {aeks_dir}\")\n",
    "        return {}, []\n",
    "\n",
    "    for eks_file in eks_csv_files:\n",
    "        eks_file_name = os.path.basename(eks_file)\n",
    "        \n",
    "        for sub_dir in aeks_subdirs:\n",
    "            aeks_csv_files = get_csv_files(sub_dir, file_name)\n",
    "            if not aeks_csv_files:\n",
    "                print(f\"No matching AEKS files found for {file_name} in {sub_dir}\")\n",
    "                continue\n",
    "\n",
    "            for aeks_file in aeks_csv_files:\n",
    "                aeks_file_name = os.path.basename(aeks_file)\n",
    "\n",
    "                if eks_file_name in aeks_file_name:\n",
    "                    try:\n",
    "                        error_df, top_error_df = calculate_pixel_error(eks_file, aeks_file, top_error_frame_count)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error calculating pixel error between {eks_file_name} and {aeks_file_name}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    base_file_name = os.path.splitext(eks_file_name)[0]  # Remove the original .csv extension if present\n",
    "                    sub_dir_name = os.path.basename(sub_dir) if 'eks' not in os.path.basename(sub_dir) else 'aeks_eks'\n",
    "\n",
    "                    # Save the error CSV to the relative_pixel_error directory\n",
    "                    relative_pixel_error_dir = os.path.join(output_dir, 'relative_pixel_error')\n",
    "                    if not os.path.exists(relative_pixel_error_dir):\n",
    "                        os.makedirs(relative_pixel_error_dir)\n",
    "                    error_output_file = os.path.join(relative_pixel_error_dir, f\"error_{base_file_name}_{sub_dir_name}.csv\")\n",
    "                    error_df.to_csv(error_output_file, index=False)\n",
    "\n",
    "                    # Save top error frames CSV\n",
    "                    top_error_frames_dir = os.path.join(output_dir, 'top_error_frames')\n",
    "                    if not os.path.exists(top_error_frames_dir):\n",
    "                        os.makedirs(top_error_frames_dir)\n",
    "                    top_error_frames_file = os.path.join(top_error_frames_dir, f\"top_error_frames_{base_file_name}_{sub_dir_name}.csv\")\n",
    "                    top_error_df.to_csv(top_error_frames_file, index=False)\n",
    "\n",
    "                    all_top_error_frames[f\"{base_file_name}_{sub_dir_name}\"] = top_error_df\n",
    "                    all_error_dfs.append((error_df, sub_dir_name))\n",
    "\n",
    "    return all_top_error_frames, all_error_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_video_frames(eks_dir, aeks_dir, output_dir, video_path, n_frames, file_name):\n",
    "    eks_file = get_csv_files(eks_dir, file_name)[0]\n",
    "    aeks_subdirs = get_subdirectories(aeks_dir)\n",
    "\n",
    "    # Create a parent directory for the output videos for this eks_file\n",
    "    parent_output_dir = os.path.join(output_dir, f'{base_file_name}_plotted_vids')\n",
    "    if not os.path.exists(parent_output_dir):\n",
    "        os.makedirs(parent_output_dir)\n",
    "\n",
    "    for sub_dir in aeks_subdirs:\n",
    "        aeks_csv_files = get_csv_files(sub_dir, file_name)\n",
    "        matching_aeks_files = [f for f in aeks_csv_files if f'{file_name}.csv' in os.path.basename(f)]\n",
    "\n",
    "        if not matching_aeks_files:\n",
    "            print(f\"No matching aEKS file found for {file_name} in {sub_dir}\")\n",
    "            continue\n",
    "\n",
    "        aeks_file = matching_aeks_files[0]\n",
    "\n",
    "        # Create a directory for the output videos inside the parent directory\n",
    "        output_subdir = os.path.join(parent_output_dir, os.path.basename(sub_dir))\n",
    "        if not os.path.exists(output_subdir):\n",
    "            os.makedirs(output_subdir)\n",
    "\n",
    "        # Load EKS\n",
    "        print(eks_file)\n",
    "        markers_curr = pd.read_csv(eks_file, header=[0, 1, 2], index_col=0)\n",
    "        keypoint_names = [c[1] for c in markers_curr.columns[::3]]\n",
    "        model_name = markers_curr.columns[0][0]\n",
    "        eks_pd = convert_lp_dlc(markers_curr, keypoint_names, model_name)\n",
    "\n",
    "        # Load AEKS\n",
    "        markers_curr = pd.read_csv(aeks_file, header=[0, 1, 2], index_col=0)\n",
    "        keypoint_names = [c[1] for c in markers_curr.columns[::3]]\n",
    "        model_name = markers_curr.columns[0][0]\n",
    "        eks_pd2 = convert_lp_dlc(markers_curr, keypoint_names, model_name)\n",
    "\n",
    "        # Setup for plotting\n",
    "        animal_ids = [1]\n",
    "        body_parts = ['tailMid_bot']  # Add other body parts as needed\n",
    "        to_plot = []\n",
    "        for animal_id in animal_ids:\n",
    "            for body_part in body_parts:\n",
    "                to_plot.append(body_part)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        start_frame = 1\n",
    "        idxs = np.arange(start_frame, start_frame + n_frames)\n",
    "        framerate = 20\n",
    "\n",
    "        colors = ['cyan', 'pink']\n",
    "        alphas = [.8, 1.0]\n",
    "        markers = ['.', 'x']\n",
    "        model_labels = ['AEKS', 'EKS']\n",
    "        model_colors = colors\n",
    "\n",
    "        for body_part in to_plot:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "            tmp_dir = os.path.join(output_subdir, f'tmp_{body_part}')\n",
    "            if not os.path.exists(tmp_dir):\n",
    "                os.makedirs(tmp_dir)\n",
    "            save_file = os.path.join(output_subdir, f'{base_file_name}_{body_part}.mp4')\n",
    "\n",
    "            txt_fr_kwargs = {\n",
    "                'fontsize': 14, 'color': [1, 1, 1], 'horizontalalignment': 'left',\n",
    "                'verticalalignment': 'top', 'fontname': 'monospace',\n",
    "                'bbox': dict(facecolor='k', alpha=0.25, edgecolor='none'),\n",
    "                'transform': ax.transAxes\n",
    "            }\n",
    "            save_imgs = True\n",
    "            markersize = 18 if save_imgs else 12\n",
    "            for idx in tqdm(range(len(idxs))):\n",
    "                n = idxs[idx]\n",
    "                ax.clear()\n",
    "                frame = get_frames_from_idxs(cap, [n])\n",
    "                ax.imshow(frame[0, 0], vmin=0, vmax=255, cmap='gray')\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                patches = []\n",
    "\n",
    "                # AEKS\n",
    "                plot_video_markers(eks_pd2, ax, n, body_part, colors[0], alphas, markers, model_id=0, markersize=markersize)\n",
    "                # EKS\n",
    "                plot_video_markers(eks_pd, ax, n, body_part, colors[1], alphas, markers, model_id=1, markersize=markersize)\n",
    "\n",
    "                # Legend\n",
    "                for i, model_label in enumerate(model_labels):\n",
    "                    patches.append(mpatches.Patch(color=model_colors[i], label=model_label))\n",
    "                ax.legend(handles=patches, prop={'size': 12}, loc='upper right')\n",
    "                im = ax.text(0.02, 0.98, f'frame {n}', **txt_fr_kwargs)\n",
    "                plt.savefig(os.path.join(tmp_dir, 'frame_%06d.jpeg' % idx))\n",
    "            save_video(save_file, tmp_dir, framerate, frame_pattern='frame_%06d.jpeg')\n",
    "            # Clean up temporary directory\n",
    "            for file in os.listdir(tmp_dir):\n",
    "                os.remove(os.path.join(tmp_dir, file))\n",
    "            os.rmdir(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_error_frames(video_path, eks_dir, aeks_dir, output_dir, top_error_frames):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    for key in top_error_frames:\n",
    "        base_file_name, sub_dir = key.split('_', 1)\n",
    "        top_error_df = top_error_frames[key]\n",
    "        subdirectory_name = f\"{base_file_name}_{sub_dir}\"\n",
    "        \n",
    "        top_error_frames_subdir = os.path.join(output_dir, 'top_error_frames', subdirectory_name)\n",
    "        if not os.path.exists(top_error_frames_subdir):\n",
    "            os.makedirs(top_error_frames_subdir)\n",
    "        \n",
    "        for _, row in top_error_df.iterrows():\n",
    "            keypoint = row['keypoint']\n",
    "            frame_idx = row['frame']\n",
    "            error = row['error']\n",
    "            \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                print(f\"Failed to read frame {frame_idx}\")\n",
    "                continue\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "            ax.imshow(frame, vmin=0, vmax=255)\n",
    "            ax.set_title(f\"Frame {frame_idx} - {keypoint} - Error: {error:.2f}\")\n",
    "            ax.axis('off')\n",
    "\n",
    "            output_file = os.path.join(top_error_frames_subdir, f\"frame_{frame_idx}_{keypoint}.png\")\n",
    "            plt.savefig(output_file, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved overlay frame plot to {output_file}\")\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pixel_error_vs_ensemble_variance(error_data, ensemble_variance_csv, output_dir, file_name, excluded_keypoints=None):\n",
    "    ensemble_variance_df = pd.read_csv(ensemble_variance_csv)\n",
    "    \n",
    "    if excluded_keypoints is None:\n",
    "        excluded_keypoints = []\n",
    "\n",
    "    def plot_filtered_error_data(filtered_error_data, title_suffix):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        aeks_eks_plotted = False\n",
    "        aeks_plotted = False\n",
    "\n",
    "        for model_name, error_df in filtered_error_data.items():\n",
    "            combined_errors = []\n",
    "            combined_variance = []\n",
    "            keypoints = error_df.columns\n",
    "\n",
    "            for keypoint in keypoints:\n",
    "                if keypoint in excluded_keypoints:\n",
    "                    continue\n",
    "\n",
    "                errors = error_df[keypoint].dropna()\n",
    "                ensemble_variance = ensemble_variance_df[keypoint].dropna()\n",
    "\n",
    "                if len(errors) == 0 or len(ensemble_variance) == 0:\n",
    "                    continue\n",
    "\n",
    "                combined_errors.extend(errors)\n",
    "                combined_variance.extend(ensemble_variance)\n",
    "\n",
    "            if len(combined_errors) == 0 or len(combined_variance) == 0:\n",
    "                continue\n",
    "\n",
    "            combined_errors = np.array(combined_errors)\n",
    "            combined_variance = np.array(combined_variance)\n",
    "\n",
    "            sorted_indices = np.argsort(combined_variance)\n",
    "            sorted_combined_variance = combined_variance[sorted_indices]\n",
    "            sorted_combined_errors = combined_errors[sorted_indices]\n",
    "            avg_sorted_combined_errors = expanding_mean(sorted_combined_errors)\n",
    "\n",
    "            # Define colors and labels\n",
    "            if 'aeks_eks' in model_name:\n",
    "                color = 'cyan'\n",
    "                label = f'{title_suffix}_aeks_eks' if not aeks_eks_plotted else None\n",
    "                aeks_eks_plotted = True\n",
    "            else:\n",
    "                color = 'gray'\n",
    "                label = f'{title_suffix}_aeks' if not aeks_plotted else None\n",
    "                aeks_plotted = True\n",
    "\n",
    "            plt.plot(sorted_combined_variance, avg_sorted_combined_errors, label=label, color=color)\n",
    "\n",
    "        plt.xlabel('Cumulative Ensemble Variance')\n",
    "        plt.ylabel('Average Pixel Error')\n",
    "        plt.title(f'EKS-relative Pixel Error vs Ensemble Variance for {title_suffix}')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        combined_plot_output_file = os.path.join(output_dir, f'pixel_error_vs_ensemble_variance_{title_suffix}.png')\n",
    "        plt.savefig(combined_plot_output_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f'Saved combined plot for all keypoints to {combined_plot_output_file}')\n",
    "\n",
    "    plot_filtered_error_data(error_data, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test_vid...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 5 pixel error files into DataFrame.\n",
      "Processing test_vid_new...\n",
      "Read 5 pixel error files into DataFrame.\n"
     ]
    }
   ],
   "source": [
    "if len(file_names) == 0:\n",
    "    print(\"No file names provided. Searching for all .mp4 files in the video directory...\")\n",
    "    file_names = find_unique_mp4_basenames(videos_dir)\n",
    "    print(f\"Found {len(file_names)} .mp4 files\")\n",
    "\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(f\"Processing {file_name}...\")\n",
    "\n",
    "    # Create the base output directory with the specified name\n",
    "    base_output_dir = os.path.join(output_dir, f'{file_name}')\n",
    "    top_error_frames_dir = os.path.join(base_output_dir, 'top_error_frames')\n",
    "    relative_pixel_error_dir = os.path.join(base_output_dir, 'relative_pixel_error')\n",
    "\n",
    "    # Ensure the directories exist\n",
    "    if not os.path.exists(top_error_frames_dir):\n",
    "        os.makedirs(top_error_frames_dir)\n",
    "    if not os.path.exists(relative_pixel_error_dir):\n",
    "        os.makedirs(relative_pixel_error_dir)\n",
    "\n",
    "    # Find path to video\n",
    "    base_file_name = os.path.splitext(file_name)[0]  # Remove file extension\n",
    "    video_path = find_matching_video(videos_dir, base_file_name)\n",
    "    if not video_path:\n",
    "        print(f\"No matching video found for {file_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Generate error files (Ensure these functions are defined and working correctly)\n",
    "    top_error_frames, all_error_dfs = calculate_errors_main(eks_dir, aeks_dir, base_output_dir, file_name, top_error_frame_count)\n",
    "    \n",
    "    # Read the error files\n",
    "    error_data = read_error_files(relative_pixel_error_dir, file_name)\n",
    "    \n",
    "    # # # Old, see pixel_error_plotting_versatile for pixel error plotting using outputs from this notebook\n",
    "    # Plot pixel error vs ensemble variance using the created CSV\n",
    "    # plot_pixel_error_vs_ensemble_variance(error_data, summed_ensemble_variance_csv_path, base_output_dir, file_name, excluded_keypoints)\n",
    "    # # #\n",
    "\n",
    "    # Plot video frames with high pixel error\n",
    "    # plot_video_frames(eks_dir, aeks_dir, base_output_dir, video_path, n_frames, file_name)\n",
    "\n",
    "    # Plot top error frames\n",
    "    # plot_top_error_frames(video_path, eks_dir, aeks_dir, base_output_dir, top_error_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
